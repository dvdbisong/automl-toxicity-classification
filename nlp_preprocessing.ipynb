{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hmV3aTSHR96U"
   },
   "source": [
    "# Preparing the Dataset forÂ Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-G-PWJ5VR2mC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Copying gs://plb-ecg-automl-toxicity-demo-2021-03/train.csv...\n",
      "\n",
      "Operation completed over 1 objects/65.6 MiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://plb-ecg-automl-toxicity-demo-2021-03/train.csv ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "14-7o_01R2mG"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oZLYdLqDR2mI",
    "outputId": "ea25a7e2-5f7d-43b1-ab01-8f6337cc21af"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "athKJuPER2mN"
   },
   "outputs": [],
   "source": [
    "# add clean column label\n",
    "data['clean'] = (1 - data.iloc[:, 2:].sum(axis=1) >= 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wwxU_PgR2mP"
   },
   "outputs": [],
   "source": [
    "# merge all other non-clean commnents to toxic\n",
    "data.loc[data['clean'] == 0, ['toxic']] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZ0JJW-OR2mR"
   },
   "outputs": [],
   "source": [
    "# select dataframe of clean examples\n",
    "data_clean = data[data['clean'] == 1].sample(n=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOmkWc5qR2mU"
   },
   "outputs": [],
   "source": [
    "# select dataframe of toxic examples\n",
    "data_toxic = data[data['toxic'] == 1].sample(n=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWsH9LdfR2mW"
   },
   "outputs": [],
   "source": [
    "# join into one dataframe\n",
    "data = pd.concat([data_clean, data_toxic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C3erfpExR2mZ"
   },
   "outputs": [],
   "source": [
    "# remove unused columns\n",
    "data.drop(['severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TEYvJEdQR2mc"
   },
   "outputs": [],
   "source": [
    "# data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NKZY45qrR2mf"
   },
   "outputs": [],
   "source": [
    "for index, row in data.iterrows():\n",
    "    comment_text = re.sub(r'[^\\w\\s]','',row['comment_text']).rstrip().lstrip().strip()\n",
    "    classes = ''\n",
    "    if (row['toxic'] == 1):\n",
    "        classes = 'toxic'\n",
    "    else:\n",
    "        classes = 'clean'\n",
    "    \n",
    "    pathlib.Path(\"./file/{}\".format(classes)).mkdir(parents=True, exist_ok=True) \n",
    "    with open(\"./file/{}/text_{}.txt\".format(classes,index), \"w\") as text_file:\n",
    "        text_file.write(comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ftp0AnuaR2mh"
   },
   "outputs": [],
   "source": [
    "data_path = []\n",
    "directory = 'file/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AzvM7URiR2ml"
   },
   "outputs": [],
   "source": [
    "# create data csv\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        filepath = subdir + os.sep + file\n",
    "\n",
    "        if filepath.endswith(\".txt\"):\n",
    "            entry = ['{}/{}'.format('gs://plb-ecg-automl-toxicity-demo-2021-03',filepath), os.path.basename(subdir)]\n",
    "            data_path.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mjmGeIhR2mr"
   },
   "outputs": [],
   "source": [
    "# convert to Pandas DataFrame\n",
    "data_pd = pd.DataFrame(np.array(data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OPqLHmlzR2mu"
   },
   "outputs": [],
   "source": [
    "# export data to csv\n",
    "data_pd.to_csv(\"data.csv\", header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move to cloud storage\n",
    "!gsutil -m -q cp -r file data.csv gs://plb-ecg-automl-toxicity-demo-2021-03/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo Done!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hmV3aTSHR96U"
   ],
   "name": "nlp_preprocessing.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}